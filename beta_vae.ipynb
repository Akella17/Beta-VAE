{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mx0EBU0cmvF"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSprites Dataset\n",
    "\n",
    "[dSprites](https://github.com/deepmind/dsprites-dataset) is a dataset of 2D shapes procedurally generated from 6 ground truth independent latent factors. These factors are color, shape, scale, rotation, x and y positions of a sprite.\n",
    "\n",
    "All possible combinations of these latents are present exactly once, generating N = 737280 total images.\n",
    "\n",
    "* Color: white\n",
    "* Shape: square, ellipse, heart\n",
    "* Scale: 6 values linearly spaced in [0.5, 1]\n",
    "* Orientation: 40 values in [0, 2 pi]\n",
    "* Position X: 32 values in [0, 1]\n",
    "* Position Y: 32 values in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_zip = np.load('dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `imgs` : (737280 x 64 x 64, uint8) Images in black and white.\n",
    "- `latents_values` : (737280 x 6, float64) Values of the latent factors.\n",
    "- `latents_classes` : (737280 x 6, int64) Integer index of the latent factor values. Useful as classification targets.\n",
    "- `metadata` : some additional information, including the possible latent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20155,
     "status": "ok",
     "timestamp": 1545325559544,
     "user": {
      "displayName": "AKELLA RAVI TEJ",
      "photoUrl": "",
      "userId": "17128855810653771666"
     },
     "user_tz": -330
    },
    "id": "ZRIbNhoic_gf",
    "outputId": "23ed8a60-d0c0-4420-cab0-9e5f9c52f400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: ['metadata', 'imgs', 'latents_classes', 'latents_values']\n"
     ]
    }
   ],
   "source": [
    "print('Keys in the dataset:', dataset_zip.keys())\n",
    "imgs = dataset_zip['imgs']                             # imgs: (737280 x 64 x 64, uint8) Images in black and white.\n",
    "latents_values = dataset_zip['latents_values']         # latents_values : (737280 x 6, float64) Values of the latent factors.\n",
    "latents_classes = dataset_zip['latents_classes']       # latents_classes: (737280 x 6, int64) Integer index of the latent factor values. Useful as classification targets.\n",
    "metadata = dataset_zip['metadata'][()]                 # metadata: some additional information, including the possible latent values.\n",
    "\n",
    "#print('Metadata: \\n', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnGo11qEdcas"
   },
   "outputs": [],
   "source": [
    "# Define number of values per latents and functions to convert to indices\n",
    "latents_sizes = metadata['latents_sizes'] # latents_sizes = [ 1  3  6 40 32 32]\n",
    "latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:], np.array([1,]))) # latents_bases = [737280 245760  40960   1024     32      1]\n",
    "n_samples = latents_bases[0]\n",
    "\n",
    "def latent_to_index(latents):\n",
    "    return np.dot(latents, latents_bases).astype(int)\n",
    "\n",
    "\n",
    "def sample_latent(size=1):\n",
    "    samples = np.zeros((size, latents_sizes.size))\n",
    "    for lat_i, lat_size in enumerate(latents_sizes):\n",
    "        samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_Bb2MAKdipp"
   },
   "outputs": [],
   "source": [
    "# image getter methods\n",
    "def sample_image(shape = 0, scale = 0, orientation = 0, x = 0, y = 0):\n",
    "    latents = [0, shape, scale, orientation, x, y]\n",
    "    index = np.dot(latents, self.latents_bases).astype(int)\n",
    "    return get_images([index])[0]\n",
    "\n",
    "def sample_images(indices):\n",
    "    images = []\n",
    "    for index in indices:\n",
    "        img = imgs[index]\n",
    "        img = img.reshape(4096)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def sample_random_images(size):\n",
    "    indices = [np.random.randint(n_samples) for i in range(size)]\n",
    "    return sample_images(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYo0FfDldldg"
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = 64\n",
    "beta = 1000\n",
    "capacity_limit = 25.0\n",
    "capacity_change_duration = 100000\n",
    "learning_rate = 5e-4\n",
    "checkpoint_dir = \"./beta_checkpoints\"\n",
    "log_file = \"log_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "- Input(4096, flattened) -> FC(1200) -> FC(1200) -> FC(10) -> FC(1200) -> FC(1200) -> FC(1200) -> FC(4096)\n",
    "- ReLU activations are used throughout.\n",
    "- Adam optimiser with a learning rate of 5e-4 is used to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dtgio-97dovu"
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "inputs_ = tf.layers.Flatten()(tf.placeholder(tf.float32, (None, 64,64,1), name=\"input\")) # Input placeholder\n",
    "capacity = tf.placeholder(tf.float32, shape=[]) # Encoding capcity\n",
    "\n",
    "with tf.variable_scope(\"Encoder\"):\n",
    "    fc1 = tf.layers.dense(inputs_, 1200, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc2 = tf.layers.dense(fc1, 1200, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc3 = tf.layers.dense(fc2, 20, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    mean = fc3[:,:10]\n",
    "    log_std_dev = tf.clip_by_value(fc3[:,10:],1e-8,5)\n",
    "\n",
    "eps = tf.random_normal( tf.shape(mean), 0, 1, dtype=tf.float32 )\n",
    "z = tf.add(mean, tf.multiply(tf.sqrt(tf.exp(log_std_dev)), eps)) # z = mu + sigma * epsilon\n",
    "\n",
    "with tf.variable_scope(\"Decoder\"):\n",
    "    fc4 = tf.layers.dense(z, 1200, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc5 = tf.layers.dense(fc4, 1200, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    fc6 = tf.layers.dense(fc5, 1200, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    reconstruct_logit = tf.layers.dense(fc6, 4096, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    reconstruct = tf.nn.sigmoid(reconstruct_logit)\n",
    "with tf.variable_scope(\"Loss\"):\n",
    "    reconstr_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = inputs_, logits = reconstruct_logit),1)) # Reconstruction loss\n",
    "    latent_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + 2*log_std_dev - tf.square(mean) - tf.square(tf.exp(log_std_dev)),1)) # Latent loss\n",
    "    loss = reconstr_loss + beta * tf.abs(latent_loss - capacity)\n",
    "    \n",
    "    reconstr_loss_summary_op = tf.summary.scalar('reconstr_loss', reconstr_loss)\n",
    "    latent_loss_summary_op   = tf.summary.scalar('latent_loss',   latent_loss)\n",
    "    summary_op = tf.summary.merge([reconstr_loss_summary_op, latent_loss_summary_op])\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiE0JrlTovlE"
   },
   "outputs": [],
   "source": [
    "# helping functions\n",
    "def _calc_encoding_capacity(step):\n",
    "    if step > capacity_change_duration:\n",
    "        c = capacity_limit\n",
    "    else:\n",
    "        c = capacity_limit * (step / capacity_change_duration)\n",
    "    return c\n",
    "\n",
    "def batch_train(sess, xs, step):\n",
    "    c = _calc_encoding_capacity(step)\n",
    "    _, reconstruction_loss, latent_z_loss, summary_str = sess.run((optimizer, reconstr_loss, latent_loss, summary_op), feed_dict={inputs_ : xs, capacity : c})\n",
    "    return reconstruction_loss, latent_z_loss, summary_str\n",
    "  \n",
    "def input_to_output(sess, xs):\n",
    "    # Original VAE output\n",
    "    return sess.run(reconstruct, feed_dict={inputs_: xs})\n",
    "\n",
    "def input_to_latent(sess, xs):\n",
    "    return sess.run([mean, log_std_dev], feed_dict={inputs_: xs})\n",
    "\n",
    "def latent_to_output(sess, zs):\n",
    "    \"\"\" Generate data by sampling from latent space. \"\"\"\n",
    "    return sess.run(reconstruct, feed_dict={z: zs})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14403,
     "status": "ok",
     "timestamp": 1545325567750,
     "user": {
      "displayName": "AKELLA RAVI TEJ",
      "photoUrl": "",
      "userId": "17128855810653771666"
     },
     "user_tz": -330
    },
    "id": "yyWT5ZpX9WfU",
    "outputId": "cad799f3-9a89-480a-bf14-6e17a244dba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520\n"
     ]
    }
   ],
   "source": [
    "total_batch = n_samples // batch_size\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8088
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6105881,
     "status": "error",
     "timestamp": 1545317201184,
     "user": {
      "displayName": "AKELLA RAVI TEJ",
      "photoUrl": "",
      "userId": "17128855810653771666"
     },
     "user_tz": -330
    },
    "id": "uqfKybmO0gmk",
    "outputId": "fbbf56d3-b644-416a-bf32-3596fbc3a0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step count: 0 time: 1sec reconstruction loss: 2838.9702 latent loss: 0.4028828 capacity: 0.0\n",
      "step count: 1000 time: 13sec reconstruction loss: 543.4658 latent loss: 0.3408327 capacity: 0.25\n",
      "step count: 2000 time: 14sec reconstruction loss: 493.11334 latent loss: 0.54778117 capacity: 0.5\n",
      "step count: 3000 time: 13sec reconstruction loss: 483.64294 latent loss: 0.90990674 capacity: 0.75\n",
      "step count: 4000 time: 13sec reconstruction loss: 487.61887 latent loss: 1.1022894 capacity: 1.0\n",
      "step count: 5000 time: 13sec reconstruction loss: 409.75787 latent loss: 1.1762537 capacity: 1.25\n",
      "step count: 6000 time: 14sec reconstruction loss: 386.47943 latent loss: 1.4615921 capacity: 1.5\n",
      "step count: 7000 time: 13sec reconstruction loss: 405.71588 latent loss: 1.768379 capacity: 1.7500000000000002\n",
      "step count: 8000 time: 13sec reconstruction loss: 448.90472 latent loss: 2.0521615 capacity: 2.0\n",
      "step count: 9000 time: 13sec reconstruction loss: 391.42023 latent loss: 2.3645582 capacity: 2.25\n",
      "step count: 10000 time: 13sec reconstruction loss: 359.39856 latent loss: 2.717181 capacity: 2.5\n",
      "step count: 11000 time: 14sec reconstruction loss: 401.80786 latent loss: 2.695938 capacity: 2.75\n",
      "------------------------------epoch: 0 reconstruction loss: 443.7620311737061 latent loss: 1.4453586688330688------------------------------\n",
      "step count: 12000 time: 38sec reconstruction loss: 341.78708 latent loss: 3.1418645 capacity: 3.0\n",
      "step count: 13000 time: 14sec reconstruction loss: 334.56653 latent loss: 3.445213 capacity: 3.25\n",
      "step count: 14000 time: 13sec reconstruction loss: 308.18527 latent loss: 3.6870294 capacity: 3.5000000000000004\n",
      "step count: 15000 time: 13sec reconstruction loss: 298.61 latent loss: 3.6706724 capacity: 3.75\n",
      "step count: 16000 time: 13sec reconstruction loss: 345.5608 latent loss: 3.8750215 capacity: 4.0\n",
      "step count: 17000 time: 13sec reconstruction loss: 278.1943 latent loss: 4.333742 capacity: 4.25\n",
      "step count: 18000 time: 14sec reconstruction loss: 282.1024 latent loss: 4.317607 capacity: 4.5\n",
      "step count: 19000 time: 13sec reconstruction loss: 283.27338 latent loss: 5.072704 capacity: 4.75\n",
      "step count: 20000 time: 13sec reconstruction loss: 285.71652 latent loss: 4.9671397 capacity: 5.0\n",
      "step count: 21000 time: 13sec reconstruction loss: 298.12146 latent loss: 5.2838135 capacity: 5.25\n",
      "step count: 22000 time: 14sec reconstruction loss: 261.28314 latent loss: 5.632065 capacity: 5.5\n",
      "step count: 23000 time: 13sec reconstruction loss: 275.4394 latent loss: 5.5328946 capacity: 5.75\n",
      "------------------------------epoch: 1 reconstruction loss: 312.14162089692223 latent loss: 4.320325529389083------------------------------\n",
      "step count: 24000 time: 39sec reconstruction loss: 265.02567 latent loss: 6.180303 capacity: 6.0\n",
      "step count: 25000 time: 14sec reconstruction loss: 255.55502 latent loss: 6.0647182 capacity: 6.25\n",
      "step count: 26000 time: 13sec reconstruction loss: 265.61078 latent loss: 6.1292543 capacity: 6.5\n",
      "step count: 27000 time: 13sec reconstruction loss: 283.7134 latent loss: 6.4544477 capacity: 6.75\n",
      "step count: 28000 time: 13sec reconstruction loss: 254.82521 latent loss: 6.6969037 capacity: 7.000000000000001\n",
      "step count: 29000 time: 14sec reconstruction loss: 252.44043 latent loss: 7.286319 capacity: 7.249999999999999\n",
      "step count: 30000 time: 13sec reconstruction loss: 235.71518 latent loss: 7.4423532 capacity: 7.5\n",
      "step count: 31000 time: 13sec reconstruction loss: 233.88097 latent loss: 7.7410045 capacity: 7.75\n",
      "step count: 32000 time: 13sec reconstruction loss: 243.55396 latent loss: 7.9360995 capacity: 8.0\n",
      "step count: 33000 time: 14sec reconstruction loss: 243.20123 latent loss: 8.160993 capacity: 8.25\n",
      "step count: 34000 time: 13sec reconstruction loss: 236.63957 latent loss: 8.675827 capacity: 8.5\n",
      "------------------------------epoch: 2 reconstruction loss: 249.8180521580908 latent loss: 7.20176447501613------------------------------\n",
      "step count: 35000 time: 38sec reconstruction loss: 229.28937 latent loss: 8.731929 capacity: 8.75\n",
      "step count: 36000 time: 14sec reconstruction loss: 212.1626 latent loss: 8.430028 capacity: 9.0\n",
      "step count: 37000 time: 13sec reconstruction loss: 221.63776 latent loss: 9.138033 capacity: 9.25\n",
      "step count: 38000 time: 13sec reconstruction loss: 197.14444 latent loss: 9.587881 capacity: 9.5\n",
      "step count: 39000 time: 13sec reconstruction loss: 213.04979 latent loss: 9.669609 capacity: 9.75\n",
      "step count: 40000 time: 14sec reconstruction loss: 235.96075 latent loss: 10.38756 capacity: 10.0\n",
      "step count: 41000 time: 13sec reconstruction loss: 212.0692 latent loss: 10.513367 capacity: 10.25\n",
      "step count: 42000 time: 13sec reconstruction loss: 223.19841 latent loss: 10.113746 capacity: 10.5\n",
      "step count: 43000 time: 13sec reconstruction loss: 206.37503 latent loss: 10.652097 capacity: 10.75\n",
      "step count: 44000 time: 13sec reconstruction loss: 212.19084 latent loss: 11.002264 capacity: 11.0\n",
      "step count: 45000 time: 14sec reconstruction loss: 188.53519 latent loss: 12.028339 capacity: 11.25\n",
      "step count: 46000 time: 13sec reconstruction loss: 187.30998 latent loss: 11.411142 capacity: 11.5\n",
      "------------------------------epoch: 3 reconstruction loss: 210.18773673507903 latent loss: 10.078549280886849------------------------------\n",
      "step count: 47000 time: 38sec reconstruction loss: 196.62897 latent loss: 11.889914 capacity: 11.75\n",
      "step count: 48000 time: 13sec reconstruction loss: 187.51874 latent loss: 12.054654 capacity: 12.0\n",
      "step count: 49000 time: 13sec reconstruction loss: 181.1727 latent loss: 12.919933 capacity: 12.25\n",
      "step count: 50000 time: 13sec reconstruction loss: 194.15733 latent loss: 13.053032 capacity: 12.5\n",
      "step count: 51000 time: 13sec reconstruction loss: 183.32794 latent loss: 12.493044 capacity: 12.75\n",
      "step count: 52000 time: 14sec reconstruction loss: 178.83987 latent loss: 12.596023 capacity: 13.0\n",
      "step count: 53000 time: 13sec reconstruction loss: 202.67284 latent loss: 13.00029 capacity: 13.25\n",
      "step count: 54000 time: 13sec reconstruction loss: 170.05724 latent loss: 13.470197 capacity: 13.5\n",
      "step count: 55000 time: 13sec reconstruction loss: 172.87833 latent loss: 13.083889 capacity: 13.750000000000002\n",
      "step count: 56000 time: 14sec reconstruction loss: 185.3454 latent loss: 13.962458 capacity: 14.000000000000002\n",
      "step count: 57000 time: 13sec reconstruction loss: 178.526 latent loss: 14.055979 capacity: 14.249999999999998\n",
      "------------------------------epoch: 4 reconstruction loss: 189.20202160543866 latent loss: 12.957843397971656------------------------------\n",
      "step count: 58000 time: 38sec reconstruction loss: 165.84183 latent loss: 14.613035 capacity: 14.499999999999998\n",
      "step count: 59000 time: 14sec reconstruction loss: 165.43227 latent loss: 15.299353 capacity: 14.75\n",
      "step count: 60000 time: 13sec reconstruction loss: 156.0429 latent loss: 15.174566 capacity: 15.0\n",
      "step count: 61000 time: 13sec reconstruction loss: 198.01776 latent loss: 14.873563 capacity: 15.25\n",
      "step count: 62000 time: 13sec reconstruction loss: 176.95605 latent loss: 14.727528 capacity: 15.5\n",
      "step count: 63000 time: 14sec reconstruction loss: 149.00697 latent loss: 16.345585 capacity: 15.75\n",
      "step count: 64000 time: 13sec reconstruction loss: 154.97662 latent loss: 16.700361 capacity: 16.0\n",
      "step count: 65000 time: 13sec reconstruction loss: 197.10623 latent loss: 16.576345 capacity: 16.25\n",
      "step count: 66000 time: 13sec reconstruction loss: 180.9928 latent loss: 15.961702 capacity: 16.5\n",
      "step count: 67000 time: 13sec reconstruction loss: 179.69315 latent loss: 17.410023 capacity: 16.75\n",
      "step count: 68000 time: 14sec reconstruction loss: 161.2938 latent loss: 16.826946 capacity: 17.0\n",
      "step count: 69000 time: 13sec reconstruction loss: 177.49051 latent loss: 17.735247 capacity: 17.25\n",
      "------------------------------epoch: 5 reconstruction loss: 175.55212786462573 latent loss: 15.837512974275484------------------------------\n",
      "step count: 70000 time: 49sec reconstruction loss: 153.15895 latent loss: 17.624043 capacity: 17.5\n",
      "step count: 71000 time: 13sec reconstruction loss: 167.60933 latent loss: 17.14928 capacity: 17.75\n",
      "step count: 72000 time: 13sec reconstruction loss: 182.36618 latent loss: 18.196602 capacity: 18.0\n",
      "step count: 73000 time: 13sec reconstruction loss: 174.37656 latent loss: 18.446396 capacity: 18.25\n",
      "step count: 74000 time: 14sec reconstruction loss: 176.38638 latent loss: 19.722675 capacity: 18.5\n",
      "step count: 75000 time: 13sec reconstruction loss: 168.16537 latent loss: 18.814987 capacity: 18.75\n",
      "step count: 76000 time: 13sec reconstruction loss: 163.73602 latent loss: 19.015173 capacity: 19.0\n",
      "step count: 77000 time: 13sec reconstruction loss: 173.52747 latent loss: 19.069725 capacity: 19.25\n",
      "step count: 78000 time: 14sec reconstruction loss: 166.42824 latent loss: 18.698277 capacity: 19.5\n",
      "step count: 79000 time: 13sec reconstruction loss: 163.92639 latent loss: 20.327297 capacity: 19.75\n",
      "step count: 80000 time: 13sec reconstruction loss: 148.67471 latent loss: 19.167782 capacity: 20.0\n",
      "------------------------------epoch: 6 reconstruction loss: 166.11249533626767 latent loss: 18.719956996126307------------------------------\n",
      "step count: 81000 time: 48sec reconstruction loss: 160.28299 latent loss: 20.03097 capacity: 20.25\n",
      "step count: 82000 time: 13sec reconstruction loss: 167.13606 latent loss: 20.60384 capacity: 20.5\n",
      "step count: 83000 time: 13sec reconstruction loss: 169.20523 latent loss: 20.778255 capacity: 20.75\n",
      "step count: 84000 time: 13sec reconstruction loss: 173.21608 latent loss: 20.603806 capacity: 21.0\n",
      "step count: 85000 time: 14sec reconstruction loss: 149.70462 latent loss: 21.552738 capacity: 21.25\n",
      "step count: 86000 time: 13sec reconstruction loss: 169.89279 latent loss: 21.490484 capacity: 21.5\n",
      "step count: 87000 time: 13sec reconstruction loss: 157.47488 latent loss: 22.564938 capacity: 21.75\n",
      "step count: 88000 time: 13sec reconstruction loss: 147.04955 latent loss: 23.234152 capacity: 22.0\n",
      "step count: 89000 time: 14sec reconstruction loss: 148.85507 latent loss: 22.34886 capacity: 22.25\n",
      "step count: 90000 time: 13sec reconstruction loss: 155.97525 latent loss: 23.09761 capacity: 22.5\n",
      "step count: 91000 time: 13sec reconstruction loss: 151.30875 latent loss: 23.01965 capacity: 22.75\n",
      "step count: 92000 time: 13sec reconstruction loss: 157.25899 latent loss: 23.235115 capacity: 23.0\n",
      "------------------------------epoch: 7 reconstruction loss: 159.33564171526166 latent loss: 21.59859759973155------------------------------\n",
      "step count: 93000 time: 48sec reconstruction loss: 153.83165 latent loss: 23.619404 capacity: 23.25\n",
      "step count: 94000 time: 13sec reconstruction loss: 158.88318 latent loss: 22.580584 capacity: 23.5\n",
      "step count: 95000 time: 13sec reconstruction loss: 138.22429 latent loss: 24.217987 capacity: 23.75\n",
      "step count: 96000 time: 14sec reconstruction loss: 142.30331 latent loss: 24.813023 capacity: 24.0\n",
      "step count: 97000 time: 13sec reconstruction loss: 157.04388 latent loss: 25.57749 capacity: 24.25\n",
      "step count: 98000 time: 13sec reconstruction loss: 157.98685 latent loss: 23.682968 capacity: 24.5\n",
      "step count: 99000 time: 13sec reconstruction loss: 148.5069 latent loss: 24.320803 capacity: 24.75\n",
      "step count: 100000 time: 14sec reconstruction loss: 157.31863 latent loss: 24.987095 capacity: 25.0\n",
      "step count: 101000 time: 13sec reconstruction loss: 159.04483 latent loss: 25.10323 capacity: 25.0\n",
      "step count: 102000 time: 13sec reconstruction loss: 153.18228 latent loss: 26.341198 capacity: 25.0\n",
      "step count: 103000 time: 13sec reconstruction loss: 140.65091 latent loss: 25.198305 capacity: 25.0\n",
      "------------------------------epoch: 8 reconstruction loss: 155.04347482389875 latent loss: 24.32635389086273------------------------------\n",
      "step count: 104000 time: 49sec reconstruction loss: 165.12006 latent loss: 24.72911 capacity: 25.0\n",
      "step count: 105000 time: 13sec reconstruction loss: 150.25864 latent loss: 24.786064 capacity: 25.0\n",
      "step count: 106000 time: 14sec reconstruction loss: 152.84326 latent loss: 24.938868 capacity: 25.0\n",
      "step count: 107000 time: 13sec reconstruction loss: 149.81027 latent loss: 24.597383 capacity: 25.0\n",
      "step count: 108000 time: 13sec reconstruction loss: 156.9809 latent loss: 24.993229 capacity: 25.0\n",
      "step count: 109000 time: 13sec reconstruction loss: 160.77498 latent loss: 25.950384 capacity: 25.0\n",
      "step count: 110000 time: 13sec reconstruction loss: 173.29974 latent loss: 25.304878 capacity: 25.0\n",
      "step count: 111000 time: 14sec reconstruction loss: 152.23492 latent loss: 25.115597 capacity: 25.0\n",
      "step count: 112000 time: 13sec reconstruction loss: 135.90173 latent loss: 25.947956 capacity: 25.0\n",
      "step count: 113000 time: 13sec reconstruction loss: 158.3794 latent loss: 24.531487 capacity: 25.0\n",
      "step count: 114000 time: 13sec reconstruction loss: 165.45345 latent loss: 24.89104 capacity: 25.0\n",
      "step count: 115000 time: 14sec reconstruction loss: 163.16483 latent loss: 25.299904 capacity: 25.0\n",
      "------------------------------epoch: 9 reconstruction loss: 154.07375199066269 latent loss: 24.99351519164112------------------------------\n",
      "step count: 116000 time: 50sec reconstruction loss: 153.42422 latent loss: 25.381128 capacity: 25.0\n",
      "step count: 117000 time: 14sec reconstruction loss: 156.79245 latent loss: 25.231506 capacity: 25.0\n",
      "step count: 118000 time: 13sec reconstruction loss: 159.02017 latent loss: 24.487709 capacity: 25.0\n",
      "step count: 119000 time: 13sec reconstruction loss: 152.81354 latent loss: 26.200342 capacity: 25.0\n",
      "step count: 120000 time: 13sec reconstruction loss: 160.26416 latent loss: 25.562561 capacity: 25.0\n",
      "step count: 121000 time: 14sec reconstruction loss: 151.20743 latent loss: 25.061552 capacity: 25.0\n",
      "step count: 122000 time: 13sec reconstruction loss: 149.9073 latent loss: 24.777191 capacity: 25.0\n",
      "step count: 123000 time: 13sec reconstruction loss: 150.54866 latent loss: 25.053349 capacity: 25.0\n",
      "step count: 124000 time: 13sec reconstruction loss: 142.30782 latent loss: 26.628452 capacity: 25.0\n",
      "step count: 125000 time: 13sec reconstruction loss: 145.87465 latent loss: 24.818426 capacity: 25.0\n",
      "step count: 126000 time: 14sec reconstruction loss: 149.97046 latent loss: 25.38549 capacity: 25.0\n",
      "------------------------------epoch: 10 reconstruction loss: 154.79453367590904 latent loss: 24.994487850036887------------------------------\n",
      "step count: 127000 time: 50sec reconstruction loss: 143.62172 latent loss: 24.790699 capacity: 25.0\n",
      "step count: 128000 time: 13sec reconstruction loss: 154.3349 latent loss: 25.08702 capacity: 25.0\n",
      "step count: 129000 time: 13sec reconstruction loss: 141.06616 latent loss: 24.996141 capacity: 25.0\n",
      "step count: 130000 time: 13sec reconstruction loss: 165.02774 latent loss: 24.197239 capacity: 25.0\n",
      "step count: 131000 time: 13sec reconstruction loss: 145.95544 latent loss: 24.32139 capacity: 25.0\n",
      "step count: 132000 time: 14sec reconstruction loss: 159.45149 latent loss: 25.091099 capacity: 25.0\n",
      "step count: 133000 time: 13sec reconstruction loss: 154.00026 latent loss: 24.233082 capacity: 25.0\n",
      "step count: 134000 time: 13sec reconstruction loss: 160.72409 latent loss: 24.408619 capacity: 25.0\n",
      "step count: 135000 time: 13sec reconstruction loss: 155.77655 latent loss: 25.24744 capacity: 25.0\n",
      "step count: 136000 time: 14sec reconstruction loss: 154.72922 latent loss: 25.9549 capacity: 25.0\n",
      "step count: 137000 time: 13sec reconstruction loss: 151.82686 latent loss: 24.89386 capacity: 25.0\n",
      "step count: 138000 time: 13sec reconstruction loss: 136.3031 latent loss: 23.97133 capacity: 25.0\n",
      "------------------------------epoch: 11 reconstruction loss: 155.0638524207804 latent loss: 24.9970810789201------------------------------\n",
      "step count: 139000 time: 44sec reconstruction loss: 153.4701 latent loss: 24.31964 capacity: 25.0\n",
      "step count: 140000 time: 13sec reconstruction loss: 158.1062 latent loss: 25.960876 capacity: 25.0\n",
      "step count: 141000 time: 13sec reconstruction loss: 143.26102 latent loss: 25.876568 capacity: 25.0\n",
      "step count: 142000 time: 13sec reconstruction loss: 164.67001 latent loss: 25.408474 capacity: 25.0\n",
      "step count: 143000 time: 14sec reconstruction loss: 163.21758 latent loss: 24.77353 capacity: 25.0\n",
      "step count: 144000 time: 13sec reconstruction loss: 155.00916 latent loss: 24.333237 capacity: 25.0\n",
      "step count: 145000 time: 13sec reconstruction loss: 155.68483 latent loss: 25.7933 capacity: 25.0\n",
      "step count: 146000 time: 13sec reconstruction loss: 146.14839 latent loss: 25.426834 capacity: 25.0\n",
      "step count: 147000 time: 14sec reconstruction loss: 154.72421 latent loss: 24.36625 capacity: 25.0\n",
      "step count: 148000 time: 13sec reconstruction loss: 154.65872 latent loss: 24.661848 capacity: 25.0\n",
      "step count: 149000 time: 13sec reconstruction loss: 157.97284 latent loss: 25.684118 capacity: 25.0\n",
      "------------------------------epoch: 12 reconstruction loss: 155.4597029103173 latent loss: 24.996727189256085------------------------------\n",
      "step count: 150000 time: 44sec reconstruction loss: 153.64777 latent loss: 25.490204 capacity: 25.0\n",
      "step count: 151000 time: 13sec reconstruction loss: 169.98157 latent loss: 25.425497 capacity: 25.0\n",
      "step count: 152000 time: 13sec reconstruction loss: 154.3328 latent loss: 25.814087 capacity: 25.0\n",
      "step count: 153000 time: 13sec reconstruction loss: 156.74135 latent loss: 24.857418 capacity: 25.0\n",
      "step count: 154000 time: 14sec reconstruction loss: 149.99979 latent loss: 24.877264 capacity: 25.0\n",
      "step count: 155000 time: 13sec reconstruction loss: 156.79883 latent loss: 25.489351 capacity: 25.0\n",
      "step count: 156000 time: 13sec reconstruction loss: 159.66779 latent loss: 24.557644 capacity: 25.0\n",
      "step count: 157000 time: 13sec reconstruction loss: 170.5764 latent loss: 24.78217 capacity: 25.0\n",
      "step count: 158000 time: 14sec reconstruction loss: 160.96036 latent loss: 25.058867 capacity: 25.0\n",
      "step count: 159000 time: 13sec reconstruction loss: 175.17407 latent loss: 25.74046 capacity: 25.0\n",
      "step count: 160000 time: 13sec reconstruction loss: 139.70947 latent loss: 25.056358 capacity: 25.0\n",
      "step count: 161000 time: 13sec reconstruction loss: 147.28926 latent loss: 24.890137 capacity: 25.0\n",
      "------------------------------epoch: 13 reconstruction loss: 156.10569444033834 latent loss: 24.999910385078856------------------------------\n",
      "step count: 162000 time: 43sec reconstruction loss: 147.4473 latent loss: 24.606873 capacity: 25.0\n",
      "step count: 163000 time: 13sec reconstruction loss: 152.86101 latent loss: 24.311842 capacity: 25.0\n",
      "step count: 164000 time: 13sec reconstruction loss: 160.8694 latent loss: 24.781775 capacity: 25.0\n",
      "step count: 165000 time: 14sec reconstruction loss: 165.40529 latent loss: 25.257687 capacity: 25.0\n",
      "step count: 166000 time: 13sec reconstruction loss: 172.10594 latent loss: 25.106718 capacity: 25.0\n",
      "step count: 167000 time: 13sec reconstruction loss: 162.29199 latent loss: 25.098278 capacity: 25.0\n",
      "step count: 168000 time: 13sec reconstruction loss: 159.41965 latent loss: 24.82843 capacity: 25.0\n",
      "step count: 169000 time: 14sec reconstruction loss: 166.88559 latent loss: 24.875528 capacity: 25.0\n",
      "step count: 170000 time: 13sec reconstruction loss: 143.76404 latent loss: 25.615847 capacity: 25.0\n",
      "step count: 171000 time: 13sec reconstruction loss: 143.1708 latent loss: 25.577541 capacity: 25.0\n",
      "step count: 172000 time: 13sec reconstruction loss: 158.15884 latent loss: 25.599142 capacity: 25.0\n",
      "------------------------------epoch: 14 reconstruction loss: 156.32420637475118 latent loss: 24.98950877437989------------------------------\n",
      "step count: 173000 time: 46sec reconstruction loss: 184.85922 latent loss: 25.611225 capacity: 25.0\n",
      "step count: 174000 time: 13sec reconstruction loss: 153.6186 latent loss: 25.010273 capacity: 25.0\n",
      "step count: 175000 time: 13sec reconstruction loss: 149.71237 latent loss: 24.761398 capacity: 25.0\n",
      "step count: 176000 time: 14sec reconstruction loss: 139.78577 latent loss: 24.598083 capacity: 25.0\n",
      "step count: 177000 time: 13sec reconstruction loss: 150.92233 latent loss: 24.54944 capacity: 25.0\n",
      "step count: 178000 time: 13sec reconstruction loss: 144.27579 latent loss: 24.236763 capacity: 25.0\n",
      "step count: 179000 time: 13sec reconstruction loss: 148.5001 latent loss: 24.70501 capacity: 25.0\n",
      "step count: 180000 time: 14sec reconstruction loss: 145.8665 latent loss: 25.033005 capacity: 25.0\n",
      "step count: 181000 time: 13sec reconstruction loss: 162.07661 latent loss: 25.123484 capacity: 25.0\n",
      "step count: 182000 time: 13sec reconstruction loss: 146.55939 latent loss: 24.80207 capacity: 25.0\n",
      "step count: 183000 time: 13sec reconstruction loss: 149.43803 latent loss: 25.14601 capacity: 25.0\n",
      "step count: 184000 time: 13sec reconstruction loss: 150.74377 latent loss: 25.837296 capacity: 25.0\n",
      "------------------------------epoch: 15 reconstruction loss: 156.45012936062284 latent loss: 25.00615481932958------------------------------\n",
      "step count: 185000 time: 55sec reconstruction loss: 145.63774 latent loss: 25.157604 capacity: 25.0\n",
      "step count: 186000 time: 14sec reconstruction loss: 138.86414 latent loss: 25.072014 capacity: 25.0\n",
      "step count: 187000 time: 13sec reconstruction loss: 153.16722 latent loss: 24.42743 capacity: 25.0\n",
      "step count: 188000 time: 13sec reconstruction loss: 158.34113 latent loss: 25.052734 capacity: 25.0\n",
      "step count: 189000 time: 13sec reconstruction loss: 159.89163 latent loss: 24.56073 capacity: 25.0\n",
      "step count: 190000 time: 14sec reconstruction loss: 179.85536 latent loss: 24.655544 capacity: 25.0\n",
      "step count: 191000 time: 13sec reconstruction loss: 167.03531 latent loss: 24.801682 capacity: 25.0\n",
      "step count: 192000 time: 13sec reconstruction loss: 150.2879 latent loss: 25.515 capacity: 25.0\n",
      "step count: 193000 time: 13sec reconstruction loss: 150.07228 latent loss: 25.456501 capacity: 25.0\n",
      "step count: 194000 time: 13sec reconstruction loss: 164.71089 latent loss: 25.711067 capacity: 25.0\n",
      "step count: 195000 time: 14sec reconstruction loss: 159.26102 latent loss: 24.463875 capacity: 25.0\n",
      "------------------------------epoch: 16 reconstruction loss: 157.13132165604168 latent loss: 25.003048148088986------------------------------\n",
      "step count: 196000 time: 45sec reconstruction loss: 143.06857 latent loss: 24.703775 capacity: 25.0\n",
      "step count: 197000 time: 14sec reconstruction loss: 148.45918 latent loss: 24.223053 capacity: 25.0\n",
      "step count: 198000 time: 13sec reconstruction loss: 171.62523 latent loss: 24.82568 capacity: 25.0\n",
      "step count: 199000 time: 13sec reconstruction loss: 157.8526 latent loss: 24.71004 capacity: 25.0\n",
      "step count: 200000 time: 13sec reconstruction loss: 152.8894 latent loss: 25.765915 capacity: 25.0\n",
      "step count: 201000 time: 14sec reconstruction loss: 163.6905 latent loss: 24.099756 capacity: 25.0\n",
      "step count: 202000 time: 13sec reconstruction loss: 157.50465 latent loss: 24.798615 capacity: 25.0\n",
      "step count: 203000 time: 13sec reconstruction loss: 157.30397 latent loss: 25.21287 capacity: 25.0\n",
      "step count: 204000 time: 13sec reconstruction loss: 148.38757 latent loss: 24.532925 capacity: 25.0\n",
      "step count: 205000 time: 14sec reconstruction loss: 155.99193 latent loss: 25.252417 capacity: 25.0\n",
      "step count: 206000 time: 13sec reconstruction loss: 152.47177 latent loss: 24.534737 capacity: 25.0\n",
      "step count: 207000 time: 13sec reconstruction loss: 141.27972 latent loss: 24.512646 capacity: 25.0\n",
      "------------------------------epoch: 17 reconstruction loss: 157.30319833887947 latent loss: 24.9964887107412------------------------------\n",
      "step count: 208000 time: 46sec reconstruction loss: 172.22496 latent loss: 25.615429 capacity: 25.0\n",
      "step count: 209000 time: 13sec reconstruction loss: 140.99786 latent loss: 24.843937 capacity: 25.0\n",
      "step count: 210000 time: 13sec reconstruction loss: 163.75998 latent loss: 24.949183 capacity: 25.0\n",
      "step count: 211000 time: 13sec reconstruction loss: 143.80696 latent loss: 25.242138 capacity: 25.0\n",
      "step count: 212000 time: 14sec reconstruction loss: 160.25757 latent loss: 24.984182 capacity: 25.0\n",
      "step count: 213000 time: 13sec reconstruction loss: 150.07236 latent loss: 24.219078 capacity: 25.0\n",
      "step count: 214000 time: 13sec reconstruction loss: 176.54425 latent loss: 24.2616 capacity: 25.0\n",
      "step count: 215000 time: 13sec reconstruction loss: 158.17851 latent loss: 25.142326 capacity: 25.0\n",
      "step count: 216000 time: 14sec reconstruction loss: 153.31009 latent loss: 24.384104 capacity: 25.0\n",
      "step count: 217000 time: 13sec reconstruction loss: 159.91928 latent loss: 24.762905 capacity: 25.0\n",
      "step count: 218000 time: 13sec reconstruction loss: 149.8048 latent loss: 25.62701 capacity: 25.0\n",
      "------------------------------epoch: 18 reconstruction loss: 158.08199600577353 latent loss: 24.995427601536115------------------------------\n",
      "step count: 219000 time: 44sec reconstruction loss: 157.65475 latent loss: 24.899992 capacity: 25.0\n",
      "step count: 220000 time: 13sec reconstruction loss: 165.09244 latent loss: 25.28226 capacity: 25.0\n",
      "step count: 221000 time: 13sec reconstruction loss: 173.44781 latent loss: 24.725574 capacity: 25.0\n",
      "step count: 222000 time: 13sec reconstruction loss: 159.07135 latent loss: 24.85343 capacity: 25.0\n",
      "step count: 223000 time: 14sec reconstruction loss: 173.0257 latent loss: 25.429234 capacity: 25.0\n",
      "step count: 224000 time: 13sec reconstruction loss: 147.85352 latent loss: 24.09092 capacity: 25.0\n",
      "step count: 225000 time: 13sec reconstruction loss: 161.72668 latent loss: 24.677525 capacity: 25.0\n",
      "step count: 226000 time: 13sec reconstruction loss: 169.66733 latent loss: 24.946594 capacity: 25.0\n",
      "step count: 227000 time: 14sec reconstruction loss: 178.70981 latent loss: 23.841846 capacity: 25.0\n",
      "step count: 228000 time: 13sec reconstruction loss: 172.87231 latent loss: 25.56253 capacity: 25.0\n",
      "step count: 229000 time: 13sec reconstruction loss: 151.26932 latent loss: 25.127428 capacity: 25.0\n",
      "step count: 230000 time: 13sec reconstruction loss: 159.42667 latent loss: 24.663174 capacity: 25.0\n",
      "------------------------------epoch: 19 reconstruction loss: 158.2028015507592 latent loss: 24.99650961591138------------------------------\n",
      "step count: 231000 time: 44sec reconstruction loss: 154.19814 latent loss: 25.166632 capacity: 25.0\n",
      "step count: 232000 time: 13sec reconstruction loss: 167.52026 latent loss: 25.002344 capacity: 25.0\n",
      "step count: 233000 time: 13sec reconstruction loss: 174.13664 latent loss: 24.821838 capacity: 25.0\n",
      "step count: 234000 time: 14sec reconstruction loss: 171.23065 latent loss: 25.041098 capacity: 25.0\n",
      "step count: 235000 time: 13sec reconstruction loss: 156.92697 latent loss: 24.854763 capacity: 25.0\n",
      "step count: 236000 time: 13sec reconstruction loss: 168.06209 latent loss: 24.235596 capacity: 25.0\n",
      "step count: 237000 time: 13sec reconstruction loss: 156.34863 latent loss: 25.213577 capacity: 25.0\n",
      "step count: 238000 time: 14sec reconstruction loss: 159.53812 latent loss: 25.44995 capacity: 25.0\n",
      "step count: 239000 time: 13sec reconstruction loss: 145.99701 latent loss: 24.985413 capacity: 25.0\n",
      "step count: 240000 time: 13sec reconstruction loss: 148.08356 latent loss: 24.639524 capacity: 25.0\n",
      "step count: 241000 time: 13sec reconstruction loss: 145.72424 latent loss: 24.294872 capacity: 25.0\n",
      "------------------------------epoch: 20 reconstruction loss: 158.53502437141208 latent loss: 25.000169982016086------------------------------\n",
      "step count: 242000 time: 50sec reconstruction loss: 168.38605 latent loss: 25.06878 capacity: 25.0\n",
      "step count: 243000 time: 13sec reconstruction loss: 158.35747 latent loss: 24.575388 capacity: 25.0\n",
      "step count: 244000 time: 13sec reconstruction loss: 167.14238 latent loss: 24.71728 capacity: 25.0\n",
      "step count: 245000 time: 14sec reconstruction loss: 160.59181 latent loss: 24.884848 capacity: 25.0\n",
      "step count: 246000 time: 13sec reconstruction loss: 153.70117 latent loss: 24.329388 capacity: 25.0\n",
      "step count: 247000 time: 13sec reconstruction loss: 161.92743 latent loss: 25.055157 capacity: 25.0\n",
      "step count: 248000 time: 13sec reconstruction loss: 184.43991 latent loss: 25.616932 capacity: 25.0\n",
      "step count: 249000 time: 14sec reconstruction loss: 164.22668 latent loss: 24.789461 capacity: 25.0\n",
      "step count: 250000 time: 13sec reconstruction loss: 170.98991 latent loss: 25.787083 capacity: 25.0\n",
      "step count: 251000 time: 13sec reconstruction loss: 167.91574 latent loss: 24.38158 capacity: 25.0\n",
      "step count: 252000 time: 13sec reconstruction loss: 162.55177 latent loss: 24.658989 capacity: 25.0\n",
      "step count: 253000 time: 14sec reconstruction loss: 174.3156 latent loss: 24.759155 capacity: 25.0\n",
      "------------------------------epoch: 21 reconstruction loss: 159.61790350940493 latent loss: 24.998976790904997------------------------------\n",
      "step count: 254000 time: 42sec reconstruction loss: 166.32288 latent loss: 25.27269 capacity: 25.0\n",
      "step count: 255000 time: 13sec reconstruction loss: 172.1042 latent loss: 25.22842 capacity: 25.0\n",
      "step count: 256000 time: 14sec reconstruction loss: 171.51637 latent loss: 24.81176 capacity: 25.0\n",
      "step count: 257000 time: 13sec reconstruction loss: 156.57661 latent loss: 25.075665 capacity: 25.0\n",
      "step count: 258000 time: 13sec reconstruction loss: 167.15358 latent loss: 24.57379 capacity: 25.0\n",
      "step count: 259000 time: 13sec reconstruction loss: 165.1984 latent loss: 25.46761 capacity: 25.0\n",
      "step count: 260000 time: 14sec reconstruction loss: 177.5323 latent loss: 24.45617 capacity: 25.0\n",
      "step count: 261000 time: 13sec reconstruction loss: 178.2945 latent loss: 24.494457 capacity: 25.0\n",
      "step count: 262000 time: 13sec reconstruction loss: 140.33731 latent loss: 25.557896 capacity: 25.0\n",
      "step count: 263000 time: 13sec reconstruction loss: 159.6651 latent loss: 24.898117 capacity: 25.0\n",
      "step count: 264000 time: 14sec reconstruction loss: 164.72067 latent loss: 24.376415 capacity: 25.0\n",
      "------------------------------epoch: 22 reconstruction loss: 160.0257255183326 latent loss: 25.00196929789252------------------------------\n",
      "step count: 265000 time: 44sec reconstruction loss: 167.34724 latent loss: 25.206314 capacity: 25.0\n",
      "step count: 266000 time: 14sec reconstruction loss: 157.36404 latent loss: 25.315872 capacity: 25.0\n",
      "step count: 267000 time: 13sec reconstruction loss: 163.94588 latent loss: 24.91205 capacity: 25.0\n",
      "step count: 268000 time: 13sec reconstruction loss: 147.69354 latent loss: 24.611313 capacity: 25.0\n",
      "step count: 269000 time: 13sec reconstruction loss: 155.43375 latent loss: 25.284473 capacity: 25.0\n",
      "step count: 270000 time: 13sec reconstruction loss: 148.99725 latent loss: 25.352133 capacity: 25.0\n",
      "step count: 271000 time: 15sec reconstruction loss: 168.00055 latent loss: 24.61614 capacity: 25.0\n",
      "step count: 272000 time: 13sec reconstruction loss: 185.499 latent loss: 25.386099 capacity: 25.0\n",
      "step count: 273000 time: 13sec reconstruction loss: 167.8638 latent loss: 24.577078 capacity: 25.0\n",
      "step count: 274000 time: 13sec reconstruction loss: 164.20877 latent loss: 25.682396 capacity: 25.0\n",
      "step count: 275000 time: 14sec reconstruction loss: 144.93047 latent loss: 25.625446 capacity: 25.0\n",
      "step count: 276000 time: 13sec reconstruction loss: 157.39742 latent loss: 24.360657 capacity: 25.0\n",
      "------------------------------epoch: 23 reconstruction loss: 160.37177058524554 latent loss: 25.00516288810306------------------------------\n",
      "step count: 277000 time: 45sec reconstruction loss: 144.08942 latent loss: 24.169323 capacity: 25.0\n",
      "step count: 278000 time: 13sec reconstruction loss: 161.93674 latent loss: 24.984022 capacity: 25.0\n",
      "step count: 279000 time: 13sec reconstruction loss: 164.25494 latent loss: 24.56641 capacity: 25.0\n",
      "step count: 280000 time: 13sec reconstruction loss: 178.56464 latent loss: 25.084915 capacity: 25.0\n",
      "step count: 281000 time: 13sec reconstruction loss: 147.50824 latent loss: 24.58623 capacity: 25.0\n",
      "step count: 282000 time: 14sec reconstruction loss: 182.22278 latent loss: 24.92218 capacity: 25.0\n",
      "step count: 283000 time: 13sec reconstruction loss: 171.3087 latent loss: 24.339977 capacity: 25.0\n",
      "step count: 284000 time: 13sec reconstruction loss: 157.42998 latent loss: 25.213829 capacity: 25.0\n",
      "step count: 285000 time: 13sec reconstruction loss: 158.2624 latent loss: 25.035696 capacity: 25.0\n",
      "step count: 286000 time: 14sec reconstruction loss: 175.02588 latent loss: 24.575226 capacity: 25.0\n",
      "step count: 287000 time: 13sec reconstruction loss: 163.30905 latent loss: 25.595875 capacity: 25.0\n",
      "------------------------------epoch: 24 reconstruction loss: 161.55372290876176 latent loss: 24.997742264303895------------------------------\n",
      "step count: 288000 time: 45sec reconstruction loss: 153.15321 latent loss: 24.73079 capacity: 25.0\n",
      "step count: 289000 time: 13sec reconstruction loss: 161.16429 latent loss: 24.893589 capacity: 25.0\n",
      "step count: 290000 time: 13sec reconstruction loss: 155.55872 latent loss: 24.398891 capacity: 25.0\n",
      "step count: 291000 time: 13sec reconstruction loss: 142.01437 latent loss: 24.838455 capacity: 25.0\n",
      "step count: 292000 time: 13sec reconstruction loss: 170.19403 latent loss: 24.950106 capacity: 25.0\n",
      "step count: 293000 time: 14sec reconstruction loss: 143.97778 latent loss: 25.022865 capacity: 25.0\n",
      "step count: 294000 time: 13sec reconstruction loss: 150.02863 latent loss: 24.906105 capacity: 25.0\n",
      "step count: 295000 time: 13sec reconstruction loss: 156.33685 latent loss: 24.888912 capacity: 25.0\n",
      "step count: 296000 time: 13sec reconstruction loss: 158.47827 latent loss: 25.656952 capacity: 25.0\n",
      "step count: 297000 time: 14sec reconstruction loss: 174.1536 latent loss: 24.970993 capacity: 25.0\n",
      "step count: 298000 time: 13sec reconstruction loss: 163.96793 latent loss: 24.890661 capacity: 25.0\n",
      "step count: 299000 time: 13sec reconstruction loss: 174.24405 latent loss: 25.085749 capacity: 25.0\n",
      "------------------------------epoch: 25 reconstruction loss: 162.60686894522772 latent loss: 25.000644922090903------------------------------\n",
      "step count: 300000 time: 45sec reconstruction loss: 147.053 latent loss: 24.958351 capacity: 25.0\n",
      "step count: 301000 time: 13sec reconstruction loss: 159.04855 latent loss: 25.318062 capacity: 25.0\n",
      "step count: 302000 time: 13sec reconstruction loss: 149.24039 latent loss: 25.783947 capacity: 25.0\n",
      "step count: 303000 time: 13sec reconstruction loss: 164.11978 latent loss: 25.010208 capacity: 25.0\n",
      "step count: 304000 time: 14sec reconstruction loss: 144.43036 latent loss: 25.182669 capacity: 25.0\n",
      "step count: 305000 time: 13sec reconstruction loss: 165.66464 latent loss: 25.10459 capacity: 25.0\n",
      "step count: 306000 time: 13sec reconstruction loss: 159.87918 latent loss: 25.095615 capacity: 25.0\n",
      "step count: 307000 time: 13sec reconstruction loss: 142.34839 latent loss: 24.783728 capacity: 25.0\n",
      "step count: 308000 time: 14sec reconstruction loss: 171.8826 latent loss: 25.00678 capacity: 25.0\n",
      "step count: 309000 time: 13sec reconstruction loss: 160.69446 latent loss: 25.30731 capacity: 25.0\n",
      "step count: 310000 time: 13sec reconstruction loss: 170.5618 latent loss: 24.753935 capacity: 25.0\n",
      "step count: 311000 time: 13sec reconstruction loss: 158.83615 latent loss: 24.769913 capacity: 25.0\n",
      "------------------------------epoch: 26 reconstruction loss: 163.258531873756 latent loss: 24.99978459295299------------------------------\n",
      "step count: 312000 time: 48sec reconstruction loss: 159.14307 latent loss: 24.798153 capacity: 25.0\n",
      "step count: 313000 time: 13sec reconstruction loss: 158.08173 latent loss: 24.535593 capacity: 25.0\n",
      "step count: 314000 time: 14sec reconstruction loss: 173.10805 latent loss: 24.67598 capacity: 25.0\n",
      "step count: 315000 time: 13sec reconstruction loss: 159.23787 latent loss: 25.364624 capacity: 25.0\n",
      "step count: 316000 time: 13sec reconstruction loss: 162.3754 latent loss: 25.554382 capacity: 25.0\n",
      "step count: 317000 time: 13sec reconstruction loss: 161.28458 latent loss: 24.571846 capacity: 25.0\n",
      "step count: 318000 time: 13sec reconstruction loss: 151.84097 latent loss: 25.33671 capacity: 25.0\n",
      "step count: 319000 time: 14sec reconstruction loss: 164.5495 latent loss: 24.78954 capacity: 25.0\n",
      "step count: 320000 time: 13sec reconstruction loss: 163.52805 latent loss: 25.10326 capacity: 25.0\n",
      "step count: 321000 time: 13sec reconstruction loss: 174.43018 latent loss: 25.310585 capacity: 25.0\n",
      "step count: 322000 time: 13sec reconstruction loss: 155.44873 latent loss: 24.890873 capacity: 25.0\n",
      "------------------------------epoch: 27 reconstruction loss: 163.91430332660676 latent loss: 24.99871562172969------------------------------\n",
      "step count: 323000 time: 45sec reconstruction loss: 161.19507 latent loss: 24.706173 capacity: 25.0\n",
      "step count: 324000 time: 13sec reconstruction loss: 151.72078 latent loss: 24.86178 capacity: 25.0\n",
      "step count: 325000 time: 14sec reconstruction loss: 185.72601 latent loss: 25.214119 capacity: 25.0\n",
      "step count: 326000 time: 13sec reconstruction loss: 180.3696 latent loss: 25.242771 capacity: 25.0\n",
      "step count: 327000 time: 13sec reconstruction loss: 168.88324 latent loss: 24.647896 capacity: 25.0\n",
      "step count: 328000 time: 13sec reconstruction loss: 195.94305 latent loss: 25.397247 capacity: 25.0\n",
      "step count: 329000 time: 13sec reconstruction loss: 170.66238 latent loss: 25.212408 capacity: 25.0\n",
      "step count: 330000 time: 14sec reconstruction loss: 159.2214 latent loss: 25.072605 capacity: 25.0\n",
      "step count: 331000 time: 13sec reconstruction loss: 183.49742 latent loss: 24.517084 capacity: 25.0\n",
      "step count: 332000 time: 13sec reconstruction loss: 149.98926 latent loss: 25.38465 capacity: 25.0\n",
      "step count: 333000 time: 13sec reconstruction loss: 160.28345 latent loss: 24.684845 capacity: 25.0\n",
      "step count: 334000 time: 14sec reconstruction loss: 170.2548 latent loss: 24.867687 capacity: 25.0\n",
      "------------------------------epoch: 28 reconstruction loss: 164.40499476061927 latent loss: 25.000380210081737------------------------------\n",
      "step count: 335000 time: 45sec reconstruction loss: 160.98083 latent loss: 25.042465 capacity: 25.0\n",
      "step count: 336000 time: 14sec reconstruction loss: 161.46068 latent loss: 25.117876 capacity: 25.0\n",
      "step count: 337000 time: 13sec reconstruction loss: 153.91136 latent loss: 25.240189 capacity: 25.0\n",
      "step count: 338000 time: 13sec reconstruction loss: 188.31686 latent loss: 24.951038 capacity: 25.0\n",
      "step count: 339000 time: 13sec reconstruction loss: 163.63861 latent loss: 24.71922 capacity: 25.0\n",
      "step count: 340000 time: 14sec reconstruction loss: 176.73416 latent loss: 24.552902 capacity: 25.0\n",
      "step count: 341000 time: 13sec reconstruction loss: 153.13297 latent loss: 25.068987 capacity: 25.0\n",
      "step count: 342000 time: 13sec reconstruction loss: 165.97836 latent loss: 25.763573 capacity: 25.0\n",
      "step count: 343000 time: 13sec reconstruction loss: 166.17545 latent loss: 24.367794 capacity: 25.0\n",
      "step count: 344000 time: 13sec reconstruction loss: 146.01015 latent loss: 25.59933 capacity: 25.0\n",
      "step count: 345000 time: 14sec reconstruction loss: 167.02661 latent loss: 25.167303 capacity: 25.0\n",
      "------------------------------epoch: 29 reconstruction loss: 164.95525213479996 latent loss: 24.99919742875629------------------------------\n",
      "step count: 346000 time: 41sec reconstruction loss: 165.50192 latent loss: 24.760788 capacity: 25.0\n",
      "step count: 347000 time: 14sec reconstruction loss: 181.367 latent loss: 24.49625 capacity: 25.0\n",
      "step count: 348000 time: 13sec reconstruction loss: 177.95284 latent loss: 25.231682 capacity: 25.0\n",
      "step count: 349000 time: 13sec reconstruction loss: 187.96597 latent loss: 25.300774 capacity: 25.0\n",
      "step count: 350000 time: 13sec reconstruction loss: 144.93706 latent loss: 25.162764 capacity: 25.0\n",
      "step count: 351000 time: 14sec reconstruction loss: 175.46759 latent loss: 24.852161 capacity: 25.0\n",
      "step count: 352000 time: 13sec reconstruction loss: 161.891 latent loss: 24.985733 capacity: 25.0\n",
      "step count: 353000 time: 13sec reconstruction loss: 164.70973 latent loss: 25.046307 capacity: 25.0\n",
      "step count: 354000 time: 13sec reconstruction loss: 180.11673 latent loss: 24.828823 capacity: 25.0\n",
      "step count: 355000 time: 13sec reconstruction loss: 162.97733 latent loss: 24.831825 capacity: 25.0\n",
      "step count: 356000 time: 14sec reconstruction loss: 156.86008 latent loss: 25.06322 capacity: 25.0\n",
      "step count: 357000 time: 13sec reconstruction loss: 153.63011 latent loss: 25.85394 capacity: 25.0\n",
      "------------------------------epoch: 30 reconstruction loss: 166.53679631683562 latent loss: 24.998524639507135------------------------------\n",
      "step count: 358000 time: 50sec reconstruction loss: 188.9523 latent loss: 24.632593 capacity: 25.0\n",
      "step count: 359000 time: 13sec reconstruction loss: 171.30283 latent loss: 24.645613 capacity: 25.0\n",
      "step count: 360000 time: 13sec reconstruction loss: 168.58878 latent loss: 25.435701 capacity: 25.0\n",
      "step count: 361000 time: 13sec reconstruction loss: 152.89322 latent loss: 25.10513 capacity: 25.0\n",
      "step count: 362000 time: 14sec reconstruction loss: 150.05186 latent loss: 25.152668 capacity: 25.0\n",
      "step count: 363000 time: 13sec reconstruction loss: 165.50845 latent loss: 24.68991 capacity: 25.0\n",
      "step count: 364000 time: 13sec reconstruction loss: 162.09329 latent loss: 24.739277 capacity: 25.0\n",
      "step count: 365000 time: 13sec reconstruction loss: 159.88597 latent loss: 25.242083 capacity: 25.0\n",
      "step count: 366000 time: 16sec reconstruction loss: 166.58667 latent loss: 24.830547 capacity: 25.0\n",
      "step count: 367000 time: 13sec reconstruction loss: 187.27826 latent loss: 25.589903 capacity: 25.0\n",
      "step count: 368000 time: 13sec reconstruction loss: 168.13025 latent loss: 24.503822 capacity: 25.0\n",
      "------------------------------epoch: 31 reconstruction loss: 166.87394090758428 latent loss: 24.9981325848235------------------------------\n",
      "step count: 369000 time: 45sec reconstruction loss: 168.88191 latent loss: 24.7315 capacity: 25.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6b3a889a4231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Fit training using batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_z_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c1aaec8ff103>\u001b[0m in \u001b[0;36mbatch_train\u001b[0;34m(sess, xs, step)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calc_encoding_capacity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_z_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_z_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training step\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(log_file, sess.graph)\n",
    "    reconstruct_check_images = sample_random_images(10)\n",
    "    indices = list(range(n_samples))\n",
    "    step = 0\n",
    "    n1=dt.datetime.now()\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(indices)\n",
    "        r_loss_term = 0\n",
    "        l_loss_term = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_indices = indices[batch_size*i : batch_size*(i+1)]\n",
    "            batch_xs = sample_images(batch_indices)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            reconstruction_loss, latent_z_loss, summary_str = batch_train(sess, batch_xs, step)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            if step%1000 == 0:\n",
    "                n2=dt.datetime.now()\n",
    "                print(\"step count: \"+str(step)+\" time: \"+str((n2-n1).seconds)+\"sec reconstruction loss: \"+str(reconstruction_loss)+\" latent loss: \"+str(latent_z_loss)+\" capacity: \"+str(_calc_encoding_capacity(step)))\n",
    "                n1 = n2\n",
    "            step += 1\n",
    "            r_loss_term += reconstruction_loss\n",
    "            l_loss_term += latent_z_loss\n",
    "        \n",
    "        print(\"------------------------------epoch: \"+str(epoch)+\" reconstruction loss: \"+str(r_loss_term/total_batch)+\" latent loss: \"+str(l_loss_term/total_batch)+\"------------------------------\")\n",
    "        # Save checkpoint\n",
    "        save_path = saver.save(sess, checkpoint_dir + '/' + 'checkpoint', global_step = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcO59UqPYnbl"
   },
   "outputs": [],
   "source": [
    "# Helper function to show images\n",
    "def show_images_grid(imgs_, num_images=25):\n",
    "  ncols = int(np.ceil(num_images**0.5))\n",
    "  nrows = int(np.ceil(num_images / ncols))\n",
    "  _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for ax_i, ax in enumerate(axes):\n",
    "    if ax_i < num_images:\n",
    "      ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "    else:\n",
    "      ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE reconstruction check\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_dir + '/' + 'checkpoint-40')\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    rand_imgs = sample_random_images(2)\n",
    "    rand_reconst_imgs = input_to_output(sess, rand_imgs).reshape(-1,64,64)\n",
    "    side_by_side = np.array(rand_imgs).reshape(-1,64,64)\n",
    "    show_images_grid([side_by_side[0],rand_reconst_imgs[0],side_by_side[1],rand_reconst_imgs[1]], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disentanglement check: sweep over the latent space\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_dir + '/' + 'checkpoint-40')\n",
    "    rand_imgs = sample_random_images(1)\n",
    "    latent_mean, latent_log_std = input_to_latent(sess, rand_imgs)\n",
    "    z_sigma_sq = np.exp(latent_log_std)[0]\n",
    "    z_mean = latent_mean[0]\n",
    "    print(\"Variance: \", end=\"\")\n",
    "    for x in z_sigma_sq:\n",
    "        print(x, end=', ')\n",
    "    \n",
    "    appended_list = []\n",
    "    for target_z_index in range(10):\n",
    "        for ri in range(10):\n",
    "            value = -3.0 + (6.0 / 9.0) * ri\n",
    "            z_mean2 = np.zeros((1, 10))\n",
    "            for i in range(10):\n",
    "                if( i == target_z_index ):\n",
    "                    z_mean2[0][i] = value\n",
    "                else:\n",
    "                    z_mean2[0][i] = z_mean[i]\n",
    "            reconstr_img = latent_to_output(sess, z_mean2)\n",
    "            rimg = reconstr_img[0].reshape(64, 64)\n",
    "            appended_list.append(rimg)\n",
    "      #imsave(\"disentangle_img/check_z{0}_{1}.png\".format(target_z_index,ri), rimg)\n",
    "    \n",
    "    show_images_grid(appended_list, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNuDqsdJst4u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "beta-vae.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
