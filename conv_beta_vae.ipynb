{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oswTUscT5Azx"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dSprites Dataset\n",
    "\n",
    "[dSprites](https://github.com/deepmind/dsprites-dataset) is a dataset of 2D shapes procedurally generated from 6 ground truth independent latent factors. These factors are color, shape, scale, rotation, x and y positions of a sprite.\n",
    "\n",
    "All possible combinations of these latents are present exactly once, generating N = 737280 total images.\n",
    "\n",
    "* Color: white\n",
    "* Shape: square, ellipse, heart\n",
    "* Scale: 6 values linearly spaced in [0.5, 1]\n",
    "* Orientation: 40 values in [0, 2 pi]\n",
    "* Position X: 32 values in [0, 1]\n",
    "* Position Y: 32 values in [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_zip = np.load('dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `imgs` : (737280 x 64 x 64, uint8) Images in black and white.\n",
    "- `latents_values` : (737280 x 6, float64) Values of the latent factors.\n",
    "- `latents_classes` : (737280 x 6, int64) Integer index of the latent factor values. Useful as classification targets.\n",
    "- `metadata` : some additional information, including the possible latent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15223,
     "status": "ok",
     "timestamp": 1545332949814,
     "user": {
      "displayName": "AKELLA RAVI TEJ",
      "photoUrl": "",
      "userId": "17128855810653771666"
     },
     "user_tz": -330
    },
    "id": "y-iujr4J5Dhp",
    "outputId": "6924cb8c-8076-48ad-bfc5-189184059325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: ['metadata', 'imgs', 'latents_classes', 'latents_values']\n"
     ]
    }
   ],
   "source": [
    "print('Keys in the dataset:', dataset_zip.keys())\n",
    "imgs = dataset_zip['imgs']                             # imgs: (737280 x 64 x 64, uint8) Images in black and white.\n",
    "latents_values = dataset_zip['latents_values']         # latents_values : (737280 x 6, float64) Values of the latent factors.\n",
    "latents_classes = dataset_zip['latents_classes']       # latents_classes: (737280 x 6, int64) Integer index of the latent factor values. Useful as classification targets.\n",
    "metadata = dataset_zip['metadata'][()]                 # metadata: some additional information, including the possible latent values.\n",
    "\n",
    "#print('Metadata: \\n', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwB8Ahw45FqQ"
   },
   "outputs": [],
   "source": [
    "# Define number of values per latents and functions to convert to indices\n",
    "latents_sizes = metadata['latents_sizes'] # latents_sizes = [ 1  3  6 40 32 32]\n",
    "latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:], np.array([1,]))) # latents_bases = [737280 245760  40960   1024     32      1]\n",
    "n_samples = latents_bases[0]\n",
    "\n",
    "def latent_to_index(latents):\n",
    "    return np.dot(latents, latents_bases).astype(int)\n",
    "\n",
    "\n",
    "def sample_latent(size=1):\n",
    "    samples = np.zeros((size, latents_sizes.size))\n",
    "    for lat_i, lat_size in enumerate(latents_sizes):\n",
    "        samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4quojQDz5Gqa"
   },
   "outputs": [],
   "source": [
    "# image getter methods\n",
    "def sample_image(shape = 0, scale = 0, orientation = 0, x = 0, y = 0):\n",
    "    latents = [0, shape, scale, orientation, x, y]\n",
    "    index = np.dot(latents, self.latents_bases).astype(int)\n",
    "    return get_images([index])[0]\n",
    "\n",
    "def sample_images(indices):\n",
    "    images = []\n",
    "    for index in indices:\n",
    "        img = imgs[index]\n",
    "        img = img.reshape(4096)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def sample_random_images(size):\n",
    "    indices = [np.random.randint(n_samples) for i in range(size)]\n",
    "    return sample_images(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5TSxpvb5Ja_"
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = 64\n",
    "beta = 1000\n",
    "capacity_limit = 25.0\n",
    "capacity_change_duration = 100000\n",
    "learning_rate = 5e-4\n",
    "checkpoint_dir = \"conv_beta_checkpoints\"\n",
    "log_file = \"conv_log_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "- The encoder for the VAEs consists of 4 convolutional layers, each with 32 channels, 4x4 kernels, and a stride of 2. This is followed by 2 fully connected layers, each of 256 units. The latent distribution consists of one fully connected layer of 20 units parametrising the mean and log standard deviation of 10 Gaussian random variables. The decoder architecture is simply the transpose of the encoder, but with the output parametrising Bernoulli distributions over the pixels.\n",
    "- ReLU activations are used throughout.\n",
    "- Adam optimiser with a learning rate of 5e-4 is used to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJizk0L55M3w"
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "with tf.variable_scope(\"beta-VAE\", reuse=tf.AUTO_REUSE):\n",
    "    inputs_ = tf.placeholder(tf.float32, (None, 64,64,1), name=\"input\") # Input placeholder\n",
    "    capacity = tf.placeholder(tf.float32, shape=[]) # Encoding capcity\n",
    "\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        conv1 = tf.layers.conv2d(inputs_, filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv2 = tf.layers.conv2d(conv1  , filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv3 = tf.layers.conv2d(conv2  , filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv4 = tf.layers.conv2d(conv3  , filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        fc1 = tf.layers.dense(tf.layers.Flatten()(conv4), 256, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        fc2 = tf.layers.dense(fc1, 256, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        fc3 = tf.layers.dense(fc2, 20, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        mean = fc3[:,:10]\n",
    "        log_std_dev = tf.clip_by_value(fc3[:,10:],1e-8,5)\n",
    "\n",
    "    eps = tf.random_normal( tf.shape(mean), 0, 1, dtype=tf.float32 )\n",
    "    z = tf.add(mean, tf.multiply(tf.sqrt(tf.exp(log_std_dev)), eps)) # z = mu + sigma * epsilon\n",
    "\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        fc4 = tf.layers.dense(z  , 256, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        fc5 = tf.layers.dense(fc4, 256, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        fc6 = tf.layers.dense(fc5, 128, activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        deconv1 = tf.layers.conv2d_transpose(tf.reshape(fc6, [-1, 2, 2, 1]), filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        deconv2 = tf.layers.conv2d_transpose(deconv1, filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        deconv3 = tf.layers.conv2d_transpose(deconv2, filters = 32, kernel_size = (4,4), strides = (2, 2), activation = tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        reconstruct_logit = tf.reshape(tf.layers.conv2d_transpose(deconv3, filters = 32, kernel_size = (4,4), strides = (2, 2), kernel_initializer=tf.contrib.layers.xavier_initializer()), [-1, 64*64*1])\n",
    "        reconstruct = tf.nn.sigmoid(reconstruct_logit)\n",
    "    with tf.variable_scope(\"Loss\"):\n",
    "        reconstr_loss = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = tf.layers.Flatten()(inputs_), logits = reconstruct_logit),1)) # Reconstruction loss\n",
    "        latent_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + 2*log_std_dev - tf.square(mean) - tf.square(tf.exp(log_std_dev)),1)) # Latent loss\n",
    "        loss = reconstr_loss + beta * tf.abs(latent_loss - capacity)\n",
    "\n",
    "        reconstr_loss_summary_op = tf.summary.scalar('reconstr_loss', reconstr_loss)\n",
    "        latent_loss_summary_op   = tf.summary.scalar('latent_loss',   latent_loss)\n",
    "        summary_op = tf.summary.merge([reconstr_loss_summary_op, latent_loss_summary_op])\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvSKVGUe5N3C"
   },
   "outputs": [],
   "source": [
    "# helping functions\n",
    "def _calc_encoding_capacity(step):\n",
    "    if step > capacity_change_duration:\n",
    "        c = capacity_limit\n",
    "    else:\n",
    "        c = capacity_limit * (step / capacity_change_duration)\n",
    "    return c\n",
    "\n",
    "def batch_train(sess, xs, step):\n",
    "    c = _calc_encoding_capacity(step)\n",
    "    _, reconstruction_loss, latent_z_loss, summary_str = sess.run((optimizer, reconstr_loss, latent_loss, summary_op), feed_dict={inputs_ : xs, capacity : c})\n",
    "    return reconstruction_loss, latent_z_loss, summary_str\n",
    "  \n",
    "def input_to_output(sess, xs):\n",
    "    # Original VAE output\n",
    "    return sess.run(reconstruct, feed_dict={inputs_: xs})\n",
    "\n",
    "def input_to_latent(sess, xs):\n",
    "    return sess.run([mean, log_std_dev], feed_dict={inputs_: xs})\n",
    "\n",
    "def latent_to_output(sess, zs):\n",
    "    \"\"\" Generate data by sampling from latent space. \"\"\"\n",
    "    return sess.run(reconstruct, feed_dict={z: zs})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22007,
     "status": "ok",
     "timestamp": 1545332957625,
     "user": {
      "displayName": "AKELLA RAVI TEJ",
      "photoUrl": "",
      "userId": "17128855810653771666"
     },
     "user_tz": -330
    },
    "id": "LPpBzWiN5UzE",
    "outputId": "5722689d-49d5-4b1d-cad1-2a0befc7ca1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11520\n"
     ]
    }
   ],
   "source": [
    "total_batch = n_samples // batch_size\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(log_file, sess.graph)\n",
    "    reconstruct_check_images = sample_random_images(10)\n",
    "    indices = list(range(n_samples))\n",
    "    step = 0\n",
    "    n1=dt.datetime.now()\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(indices)\n",
    "        r_loss_term = 0\n",
    "        l_loss_term = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_indices = indices[batch_size*i : batch_size*(i+1)]\n",
    "            batch_xs = sample_images(batch_indices)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            reconstruction_loss, latent_z_loss, summary_str = batch_train(sess, batch_xs, step)\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "            if step%1000 == 0:\n",
    "                n2=dt.datetime.now()\n",
    "                print(\"step count: \"+str(step)+\" time: \"+str((n2-n1).seconds)+\"sec reconstruction loss: \"+str(reconstruction_loss)+\" latent loss: \"+str(latent_z_loss)+\" capacity: \"+str(_calc_encoding_capacity(step)))\n",
    "                n1 = n2\n",
    "            step += 1\n",
    "            r_loss_term += reconstruction_loss\n",
    "            l_loss_term += latent_z_loss\n",
    "        \n",
    "        print(\"------------------------------epoch: \"+str(epoch)+\" reconstruction loss: \"+str(r_loss_term/total_batch)+\" latent loss: \"+str(l_loss_term/total_batch)+\"------------------------------\")\n",
    "        # Save checkpoint\n",
    "        save_path = saver.save(sess, checkpoint_dir + '/' + 'checkpoint', global_step = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aiIBBtP5cex"
   },
   "outputs": [],
   "source": [
    "# Helper function to show images\n",
    "def show_images_grid(imgs_, num_images=25):\n",
    "  ncols = int(np.ceil(num_images**0.5))\n",
    "  nrows = int(np.ceil(num_images / ncols))\n",
    "  _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for ax_i, ax in enumerate(axes):\n",
    "    if ax_i < num_images:\n",
    "      ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "    else:\n",
    "      ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ivL6_XL5dLK"
   },
   "outputs": [],
   "source": [
    "# VAE reconstruction check\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_dir + '/' + 'checkpoint-40')\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    rand_imgs = sample_random_images(2)\n",
    "    rand_reconst_imgs = input_to_output(sess, rand_imgs).reshape(-1,64,64)\n",
    "    side_by_side = np.array(rand_imgs).reshape(-1,64,64)\n",
    "    show_images_grid([side_by_side[0],rand_reconst_imgs[0],side_by_side[1],rand_reconst_imgs[1]], 4)\n",
    "    #for imgs in rand_imgs:\n",
    "        #imsave(\"reconstr_img/org_{0}.png\".format(i),      side_by_side)\n",
    "        #imsave(\"reconstr_img/reconstr_{0}.png\".format(i), rand_reconst_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcRFI7305g6j"
   },
   "outputs": [],
   "source": [
    "# Disentanglement check: sweep over the latent space\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_dir + '/' + 'checkpoint-40')\n",
    "    rand_imgs = sample_random_images(1)\n",
    "    latent_mean, latent_log_std = input_to_latent(sess, rand_imgs)\n",
    "    z_sigma_sq = np.exp(latent_log_std)[0]\n",
    "    z_mean = latent_mean[0]\n",
    "    print(\"Variance: \", end=\"\")\n",
    "    for x in z_sigma_sq:\n",
    "        print(x, end=', ')\n",
    "    \n",
    "    appended_list = []\n",
    "    for target_z_index in range(10):\n",
    "        for ri in range(10):\n",
    "            value = -3.0 + (6.0 / 9.0) * ri\n",
    "            z_mean2 = np.zeros((1, 10))\n",
    "            for i in range(10):\n",
    "                if( i == target_z_index ):\n",
    "                    z_mean2[0][i] = value\n",
    "                else:\n",
    "                    z_mean2[0][i] = z_mean[i]\n",
    "            reconstr_img = latent_to_output(sess, z_mean2)\n",
    "            rimg = reconstr_img[0].reshape(64, 64)\n",
    "            appended_list.append(rimg)\n",
    "      #imsave(\"disentangle_img/check_z{0}_{1}.png\".format(target_z_index,ri), rimg)\n",
    "    \n",
    "    show_images_grid(appended_list, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5p5XnVGBV1G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "conv_beta_vae.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
